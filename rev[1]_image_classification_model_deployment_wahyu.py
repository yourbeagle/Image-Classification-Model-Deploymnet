# -*- coding: utf-8 -*-
"""REV[1]_Image_Classification_Model_Deployment_Wahyu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bD4UWrP0WnffDLiiawGWqt8av20iMu-T

**Nama : Wahyu Bagus Wicaksono**

**Grup : M07**

Import library yang diperlukan
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Input
import numpy as np
import matplotlib.pyplot as plt
import pathlib

"""Install library kaggle untuk mendownload dataset"""

!pip install -q kaggle

"""Upload api key kamu yang sudah di download dari website kaggle"""

from google.colab import files
files.upload()

"""untuk membuat folder .kaggle dan memberikan hak akses"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""Mendownload dataset dan mengekstrak zip folder


dataset bisa di download di : https://www.kaggle.com/datasets/mostafaabla/garbage-classification
"""

!kaggle datasets download -d mostafaabla/garbage-classification -p /content/sample_data/ --unzip

"""Melihat isi folder dari dataset tersebut"""

!ls /content/sample_data/garbage_classification

"""Melabeli folder"""

import os

data = os.path.join("/content/sample_data/garbage_classification")
print(os.listdir(data))

"""Menghapus folder yang tidak kita butuhkan sebagai dataset"""

import shutil

del_data = ['clothes', 'shoes', 'white-glass', 'brown-glass', 'biological', 'trash']

for x in del_data:
  path = os.path.join(data, x)
  shutil.rmtree(path)

"""melihat isi dari folder dataset yang sudah kita rubah"""

new_data = os.listdir(data)
print(new_data)

"""Melihat total data yang akan kita gunakan pada setiap folder"""

from PIL import Image
total = 0

for x in new_data:
  dir = os.path.join(data, x)
  y = len(os.listdir(dir))
  print(x,':',y)
  total = total + y

  img_name = os.listdir(dir)
  for z in range(4):
    img_path = os.path.join(dir, img_name[z])
    img = Image.open(img_path)
    print('=',img.size)
  print("==================")

print("\nTotal Data yang digunakan :",total)

"""Proses Augmentasi Gambar"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    vertical_flip=True,
    horizontal_flip=True,
    shear_range=0.2,
    zoom_range=0.2,
    validation_split=0.2,
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_directory(
    data,
    target_size=(150,150),
    batch_size=100,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    data,
    target_size=(150,150),
    batch_size=100,
    class_mode='categorical',
    subset='validation'
)

"""Membuat Model"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')
])

optimizer = tf.keras.optimizers.Adam()
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""Callback jika akurasi sudah mencapai 90%, maka training akan di hentikan"""

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy')>0.90 and logs.get('val_accuracy')>0.9):
            print("\nAccuracy sudah diatas 90%, hentikan training\n")
            self.model.stop_training=True
callbacks = myCallback()

"""Proses Melatih Data"""

history = model.fit(train_generator,
                    epochs=100,
                    validation_data=validation_generator,
                    verbose=1,
                    callbacks=[callbacks]
)

"""Menampilkan hasil training kedalam bentuk plot agar mudah untuk dipelajari"""

plt.style.use("ggplot")
plt.figure(figsize=(10, 5))
plt.plot(np.arange(0, 100), history.history["loss"], label="training")
plt.plot(np.arange(0, 100), history.history["val_loss"], label="validation")
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.figure(figsize=(10, 5))
plt.plot(np.arange(0, 100), history.history["accuracy"], label="training")
plt.plot(np.arange(0, 100), history.history["val_accuracy"], label="validation")
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

print(train_generator.class_indices)

"""Mencoba mendeteksi gambar"""

from tensorflow.keras.preprocessing import image
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
 
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
 
  classes = model.predict(images, batch_size=10)
  output_class=np.argmax(classes)
  print(fn)
  if output_class==0:
   print('battery')
  elif output_class==1:
    print('cardboard')
  elif output_class==2:
   print('green glass')
  elif output_class==3:
   print('metal')
  elif output_class==4:
   print('paper')
  elif output_class==5:
   print('plastic')
  else:
    print("tidak diketahui")

"""Mengubah model menjadi bentuk tflite"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('model-wahyu.tflite')
tflite_model_file.write_bytes(tflite_model)